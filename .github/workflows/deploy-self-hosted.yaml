name: Build and Deploy (Self-Hosted Runner)
on:
  push:
    branches: [ main ]
  workflow_dispatch:  # Also allow manual trigger
    inputs:
      skip_tests:
        description: 'Skip tests'
        required: false
        default: false
        type: boolean
      skip_deploy:
        description: 'Skip deployment (build only)'
        required: false
        default: false
        type: boolean

jobs:
  build-and-deploy:
    runs-on: self-hosted

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Required for SonarQube analysis

      # Install Datadog CI early in the workflow
      - name: Install Datadog CI
        id: datadog_setup
        continue-on-error: true
        env:
          DD_API_KEY: ${{ secrets.DD_API_KEY }}
          DD_APP_KEY: ${{ secrets.DD_APP_KEY }}
          DD_SITE: datadoghq.com
        run: |
          echo "=========================================="
          echo "Setting up Datadog CI"
          echo "=========================================="
          
          # Check if datadog-ci.sh exists and is executable
          if [ -f "/tmp/datadog-ci.sh" ]; then
            echo "✓ Found mounted datadog-ci.sh script"
            chmod +x /tmp/datadog-ci.sh
            if /tmp/datadog-ci.sh; then
              echo "✅ Datadog CI installed successfully via script"
              echo "datadog_ci_available=true" >> $GITHUB_OUTPUT
            else
              echo "⚠️  datadog-ci.sh script failed, trying manual installation..."
            fi
          else
            echo "⚠️  /tmp/datadog-ci.sh not found, trying manual installation..."
          fi
          
          # Fallback: Try manual installation if script failed or doesn't exist
          if ! command -v datadog-ci &> /dev/null; then
            if command -v npm &> /dev/null; then
              echo "Installing datadog-ci globally..."
              npm install -g @datadog/datadog-ci
              if command -v datadog-ci &> /dev/null; then
                echo "✅ Datadog CI installed via npm"
                echo "datadog_ci_available=true" >> $GITHUB_OUTPUT
              else
                echo "❌ Failed to install datadog-ci"
                echo "datadog_ci_available=false" >> $GITHUB_OUTPUT
              fi
            else
              echo "❌ npm not available, cannot install datadog-ci"
              echo "datadog_ci_available=false" >> $GITHUB_OUTPUT
            fi
          fi
          
          # Verify installation
          if command -v datadog-ci &> /dev/null; then
            echo "✓ datadog-ci version: $(datadog-ci version)"
            echo "✓ DD_API_KEY: ${DD_API_KEY:0:8}..."
            echo "✓ DD_SITE: $DD_SITE"
          fi

      # Read VERSION file for semantic versioning
      - name: Read VERSION
        id: version
        run: |
          VERSION=$(cat VERSION | tr -d '[:space:]')
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "📦 Deployment Version: $VERSION"
      
      # ===== SonarQube Analysis with Timing Metrics =====
      # SonarQube Code Analysis (Simple approach that works)
      - name: SonarQube Scan
        uses: SonarSource/sonarqube-scan-action@v6
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}
        continue-on-error: true

      - name: SonarQube Metrics to Datadog
        id: sonarqube_metrics
        continue-on-error: true
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}
        run: |
          # Skip if no credentials
          if [ -z "$SONAR_TOKEN" ] || [ -z "$SONAR_HOST_URL" ]; then
            echo "⚠️  SonarQube credentials not configured - skipping metrics"
            exit 0
          fi

          echo "📊 Collecting SonarQube Metrics for Datadog"
          sleep 3  # Wait for processing
          
          PROJECT="quickstark_demo-fastapi_6ba235ba-ff96-459d-8607-919121b2ad98"
          METRICS=$(curl -s -u "$SONAR_TOKEN:" \
            "$SONAR_HOST_URL/api/measures/component?component=${PROJECT}&metricKeys=bugs,vulnerabilities,code_smells,coverage,duplicated_lines_density" \
            2>/dev/null) || METRICS="{}"
          
          BUGS=$(echo "$METRICS" | jq -r '.component.measures[] | select(.metric=="bugs") | .value // "0"' 2>/dev/null || echo "0")
          VULNS=$(echo "$METRICS" | jq -r '.component.measures[] | select(.metric=="vulnerabilities") | .value // "0"' 2>/dev/null || echo "0")
          SMELLS=$(echo "$METRICS" | jq -r '.component.measures[] | select(.metric=="code_smells") | .value // "0"' 2>/dev/null || echo "0")
          COVERAGE=$(echo "$METRICS" | jq -r '.component.measures[] | select(.metric=="coverage") | .value // "0"' 2>/dev/null || echo "0")

          # Send quality metrics to Datadog
          if command -v nc &> /dev/null; then
            echo "sonarqube.bugs:$BUGS|g|#project:demo-fastapi,branch:${{ github.ref_name }}" | nc -u -w1 127.0.0.1 8125 2>/dev/null || true
            echo "sonarqube.vulnerabilities:$VULNS|g|#project:demo-fastapi,branch:${{ github.ref_name }}" | nc -u -w1 127.0.0.1 8125 2>/dev/null || true
            echo "sonarqube.code_smells:$SMELLS|g|#project:demo-fastapi,branch:${{ github.ref_name }}" | nc -u -w1 127.0.0.1 8125 2>/dev/null || true
            echo "sonarqube.coverage:$COVERAGE|g|#project:demo-fastapi,branch:${{ github.ref_name }}" | nc -u -w1 127.0.0.1 8125 2>/dev/null || true
          fi

          # Quality Gate Status
          QG_STATUS=$(curl -s -u "$SONAR_TOKEN:" \
            "$SONAR_HOST_URL/api/qualitygates/project_status?projectKey=${PROJECT}" \
            | jq -r '.projectStatus.status' 2>/dev/null) || QG_STATUS="UNKNOWN"

          # Display results
          echo "📊 SonarQube Results:"
          echo "  Bugs: $BUGS"
          echo "  Vulnerabilities: $VULNS"
          echo "  Code Smells: $SMELLS"
          echo "  Coverage: $COVERAGE%"
          echo "  Quality Gate: $QG_STATUS"
      
      # ===== System Information =====
      - name: System Information
        run: |
          echo "=== System Information ==="
          echo "Hostname: $(hostname)"
          echo "User: $(whoami)"
          echo "Working Directory: $(pwd)"
          echo "OS: $(uname -a)"
          echo "=========================="
      
      - name: Check Available Tools
        run: |
          echo "=== Checking Available Tools ==="
          
          # Check Python
          if command -v python3 &> /dev/null; then
            echo "✓ Python3: $(python3 --version)"
          else
            echo "✗ Python3 not found"
          fi
          
          # Check Docker
          if command -v docker &> /dev/null; then
            echo "✓ Docker: $(docker --version)"
            if docker ps &> /dev/null; then
              echo "  ✓ Docker daemon accessible"
            else
              echo "  ✗ Docker daemon not accessible (might need socket mount)"
            fi
          else
            echo "✗ Docker not found"
          fi
          
          # Check Docker Compose
          if command -v docker-compose &> /dev/null; then
            echo "✓ Docker Compose: $(docker-compose --version)"
          else
            echo "✗ Docker Compose not found"
          fi
          
          # Check curl and other tools
          command -v curl &> /dev/null && echo "✓ curl available" || echo "✗ curl not found"
          command -v jq &> /dev/null && echo "✓ jq available" || echo "✗ jq not found"
          command -v nc &> /dev/null && echo "✓ netcat available" || echo "✗ netcat not found"
          
          echo "=========================="
      
      # ===== Testing =====
      - name: Setup Python Environment and Run Tests
        id: run_tests
        if: ${{ !inputs.skip_tests || github.event_name == 'push' }}
        continue-on-error: true
        run: |
          echo "=========================================="
          echo "Running Tests with JUnit XML Output"
          echo "=========================================="

          # Create test-results directory
          mkdir -p test-results

          # Check if we have tests to run
          if [ ! -f "requirements.txt" ]; then
            echo "⚠️  No requirements.txt found - skipping tests"
            echo "tests_generated=false" >> $GITHUB_OUTPUT
            exit 0
          fi

          if [ ! -d "tests" ]; then
            echo "⚠️  No tests directory found - skipping tests"
            echo "tests_generated=false" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "✓ Found requirements.txt"
          echo "✓ Found tests directory"
          echo "Current directory: $(pwd)"

          # Try local Python first (works better in containerized runners)
          if command -v python3 &> /dev/null; then
            echo "=========================================="
            echo "Method 1: Running tests with local Python"
            echo "=========================================="

            # Create and activate virtual environment
            echo "Setting up Python virtual environment..."
            python3 -m venv venv
            source venv/bin/activate

            # Install dependencies
            echo "Installing dependencies..."
            pip install --upgrade pip --quiet
            pip install -r requirements.txt --quiet

            # Verify pytest is installed
            if ! command -v pytest &> /dev/null; then
              echo "❌ pytest not found after installation"
              echo "tests_generated=false" >> $GITHUB_OUTPUT
              exit 1
            fi

            echo "✓ pytest version: $(pytest --version)"
            echo ""
            echo "Running tests..."

            # Run tests with proper environment variables
            MONGO_CONN=localhost \
            MONGO_USER=testuser \
            MONGO_PW=testpass \
            OPENAI_API_KEY=dummy-key-for-testing \
            SES_REGION=us-east-1 \
            SES_FROM_EMAIL=test@example.com \
            NOTION_API_KEY=dummy-key-for-testing \
            NOTION_DATABASE_ID=dummy-key-for-testing \
            AMAZON_KEY_ID=dummy-key-for-testing \
            AMAZON_KEY_SECRET=dummy-key-for-testing \
            AMAZON_S3_BUCKET=dummy-bucket-for-testing \
            BUG_REPORT_EMAIL=test@example.com \
            pytest -v --junitxml=test-results/junit.xml --tb=short || TEST_EXIT_CODE=$?

            # Check if test results were generated
            if [ -f "test-results/junit.xml" ]; then
              echo ""
              echo "✅ Test results generated: test-results/junit.xml"
              ls -lh test-results/junit.xml
              echo "tests_generated=true" >> $GITHUB_OUTPUT

              # Show test summary if xmllint available
              if command -v xmllint &> /dev/null; then
                TESTS=$(xmllint --xpath "string(//testsuite/@tests)" test-results/junit.xml 2>/dev/null || echo "?")
                FAILURES=$(xmllint --xpath "string(//testsuite/@failures)" test-results/junit.xml 2>/dev/null || echo "?")
                ERRORS=$(xmllint --xpath "string(//testsuite/@errors)" test-results/junit.xml 2>/dev/null || echo "?")
                echo "Test Summary - Tests: $TESTS, Failures: $FAILURES, Errors: $ERRORS"
              fi
            else
              echo "⚠️  No test results file generated at test-results/junit.xml"
              echo "tests_generated=false" >> $GITHUB_OUTPUT
            fi

            # Record test outcome
            if [ -n "$TEST_EXIT_CODE" ] && [ "$TEST_EXIT_CODE" != "0" ]; then
              echo "⚠️  Tests completed with exit code $TEST_EXIT_CODE"
              echo "tests_passed=false" >> $GITHUB_OUTPUT
            else
              echo "✅ All tests passed"
              echo "tests_passed=true" >> $GITHUB_OUTPUT
            fi

          else
            echo "⚠️  Python not available - cannot run tests"
            echo "tests_generated=false" >> $GITHUB_OUTPUT
            echo "tests_passed=false" >> $GITHUB_OUTPUT
          fi
      
      # Upload test results to Datadog
      - name: Upload Test Results to Datadog
        if: ${{ steps.run_tests.outputs.tests_generated == 'true' && steps.datadog_setup.outputs.datadog_ci_available == 'true' }}
        continue-on-error: true
        env:
          DD_API_KEY: ${{ secrets.DD_API_KEY }}
          DD_APP_KEY: ${{ secrets.DD_APP_KEY }}
          DD_SITE: datadoghq.com
          DD_ENV: ${{ secrets.DD_ENV }}
          DD_SERVICE: ${{ secrets.DD_SERVICE }}
        run: |
          echo "=========================================="
          echo "Uploading Test Results to Datadog"
          echo "=========================================="

          # Verify test results file exists
          if [ ! -f "test-results/junit.xml" ]; then
            echo "❌ Test results file not found at test-results/junit.xml"
            echo "Current directory: $(pwd)"
            echo "Contents of test-results directory:"
            ls -la test-results/ || echo "test-results directory not found"
            exit 1
          fi

          echo "✓ Found test results file"
          ls -lh test-results/junit.xml

          # Verify Datadog configuration
          echo "✓ Service: $DD_SERVICE"
          echo "✓ Environment: $DD_ENV"
          echo "✓ DD_API_KEY: ${DD_API_KEY:0:8}..."
          echo "✓ datadog-ci version: $(datadog-ci version)"

          # Upload test results using datadog-ci
          echo ""
          echo "Uploading to Datadog..."
          if datadog-ci junit upload \
            --service "$DD_SERVICE" \
            --env "$DD_ENV" \
            test-results/junit.xml; then
            echo ""
            echo "✅ Test results uploaded to Datadog successfully"
            echo "🔗 View in Datadog: https://app.datadoghq.com/ci/test-runs?env=$DD_ENV&service=$DD_SERVICE"
          else
            echo ""
            echo "❌ Failed to upload test results to Datadog"
            echo "Check DD_API_KEY and network connectivity"
          fi
      
      # ===== Build and Push =====
      - name: Build Docker Image
        id: docker_build
        run: |
          if command -v docker &> /dev/null && docker ps &> /dev/null; then
            echo "Building Docker image..."
            
            # Login to Docker Hub
            echo "${{ secrets.DOCKERHUB_TOKEN }}" | docker login --username "${{ secrets.DOCKERHUB_USER }}" --password-stdin
            
            # Build the image
            docker build -t quickstark/api-images:latest .
            
            # Tag with commit SHA
            docker tag quickstark/api-images:latest quickstark/api-images:${{ github.sha }}
            
            # Push to Docker Hub
            docker push quickstark/api-images:latest
            docker push quickstark/api-images:${{ github.sha }}
            
            echo "✅ Docker image built and pushed successfully"
          else
            echo "❌ Docker not available or not accessible"
            echo "If your runner is containerized, ensure Docker socket is mounted:"
            echo "  -v /var/run/docker.sock:/var/run/docker.sock"
            exit 1
          fi
      
      # ===== Deployment =====
      - name: Deploy to Local Docker
        if: ${{ !inputs.skip_deploy && steps.docker_build.outcome == 'success' }}
        run: |
          echo "=== Deploying to Local Docker on GMKTec ==="
          
          # Stop and remove existing container
          echo "Stopping existing container..."
          docker stop images-api 2>/dev/null || echo "No existing container to stop"
          docker rm -f images-api 2>/dev/null || echo "No existing container to remove"
          
          # Clean up old images to save space
          echo "Cleaning up old images..."
          docker image prune -f || true
          
          # Pull the latest image (already pushed to Docker Hub)
          echo "Pulling latest image from Docker Hub..."
          docker pull quickstark/api-images:latest
          
          # Run new container with production configuration
          echo "Starting new container..."
          docker run -d \
            --name images-api \
            --restart unless-stopped \
            -p 9000:8080 \
            --add-host=host.docker.internal:host-gateway \
            -e DD_SERVICE="${{ secrets.DD_SERVICE }}" \
            -e DD_ENV="${{ secrets.DD_ENV }}" \
            -e DD_VERSION="${{ steps.version.outputs.version }}" \
            -e DD_AGENT_HOST="${{ secrets.DD_AGENT_HOST || 'host.docker.internal' }}" \
            -e DD_PROFILING_ENABLED=true \
            -e DD_PROFILING_TIMELINE_ENABLED=true \
            -e DD_DBM_PROPAGATION_MODE=full \
            -e PGHOST="${{ secrets.PGHOST }}" \
            -e PGPORT="${{ secrets.PGPORT }}" \
            -e PGDATABASE="${{ secrets.PGDATABASE }}" \
            -e PGUSER="${{ secrets.PGUSER }}" \
            -e PGPASSWORD="${{ secrets.PGPASSWORD }}" \
            -e SQLSERVER_ENABLED="${{ secrets.SQLSERVER_ENABLED || 'true' }}" \
            -e SQLSERVERHOST="${{ secrets.SQLSERVERHOST }}" \
            -e SQLSERVERPORT="${{ secrets.SQLSERVERPORT }}" \
            -e SQLSERVERUSER="${{ secrets.SQLSERVERUSER }}" \
            -e SQLSERVERPW="${{ secrets.SQLSERVERPW }}" \
            -e SQLSERVERDB="${{ secrets.SQLSERVERDB }}" \
            -e OPENAI_API_KEY="${{ secrets.OPENAI_API_KEY }}" \
            -e DD_API_KEY="${{ secrets.DD_API_KEY }}" \
            -e DD_APP_KEY="${{ secrets.DD_APP_KEY }}" \
            -e SES_REGION="${{ secrets.SES_REGION }}" \
            -e SES_FROM_EMAIL="${{ secrets.SES_FROM_EMAIL }}" \
            -e NOTION_API_KEY="${{ secrets.NOTION_API_KEY }}" \
            -e NOTION_DATABASE_ID="${{ secrets.NOTION_DATABASE_ID }}" \
            -e AMAZON_KEY_ID="${{ secrets.AMAZON_KEY_ID }}" \
            -e AMAZON_KEY_SECRET="${{ secrets.AMAZON_KEY_SECRET }}" \
            -e AMAZON_S3_BUCKET="${{ secrets.AMAZON_S3_BUCKET }}" \
            -e MONGO_CONN="${{ secrets.MONGO_CONN }}" \
            -e MONGO_USER="${{ secrets.MONGO_USER }}" \
            -e MONGO_PW="${{ secrets.MONGO_PW }}" \
            -e BUG_REPORT_EMAIL="${{ secrets.BUG_REPORT_EMAIL }}" \
            quickstark/api-images:latest
          
          # Wait for container to start
          echo "Waiting for container to start..."
          sleep 10
          
          # Check container status
          echo "Container status:"
          docker ps | grep images-api || echo "Container not found in ps output"
          
          # Check health endpoint
          echo "Checking health endpoint..."
          if curl -f http://localhost:9000/health 2>/dev/null; then
            echo "✅ Health check passed - API is running on port 9000"
          elif curl -f http://localhost:9000/ 2>/dev/null; then
            echo "✅ Root endpoint accessible on port 9000"
          else
            echo "⚠️  Health check failed - checking container logs..."
            docker logs --tail 50 images-api
          fi
          
          echo "✅ Deployment complete!"
          echo "Application is running at: http://localhost:9000"
      
      # ===== Post-Deployment =====
      - name: Deployment Notification
        if: always()
        run: |
          if [ "${{ job.status }}" = "success" ]; then
            echo "✅ Deployment successful!"
            echo "Commit: ${{ github.sha }}"
            echo "Branch: ${{ github.ref_name }}"
            echo "Actor: ${{ github.actor }}"
          else
            echo "❌ Deployment failed!"
            echo "Check the logs above for details"
          fi
      
      # Mark Deployment in Datadog
      - name: Mark Deployment in Datadog
        if: steps.docker_build.outcome == 'success'
        continue-on-error: true
        env:
          DD_API_KEY: ${{ secrets.DD_API_KEY }}
          DD_APP_KEY: ${{ secrets.DD_APP_KEY }}
          DD_SITE: datadoghq.com
          DD_ENV: ${{ secrets.DD_ENV }}
          DD_SERVICE: ${{ secrets.DD_SERVICE }}
        run: |
          echo "=========================================="
          echo "Marking Deployment in Datadog"
          echo "=========================================="
          
          # Get short SHA for reference
          SHORT_SHA="${{ github.sha }}"
          SHORT_SHA="${SHORT_SHA:0:7}"

          echo "📦 Version: ${{ steps.version.outputs.version }}"
          echo "🔖 Git SHA: $SHORT_SHA"
          echo "🏷️  Service: $DD_SERVICE"
          echo "🌍 Environment: $DD_ENV"
          echo ""

          # Check if datadog-ci is available
          if ! command -v datadog-ci &> /dev/null; then
            echo ""
            echo "❌ ERROR: datadog-ci is not installed"
            echo ""
            echo "To fix this, SSH to your runner and install Node.js + datadog-ci:"
            echo "  docker exec -u root -it github-runner-prod bash"
            echo "  curl -fsSL https://deb.nodesource.com/setup_20.x | bash -"
            echo "  apt-get install -y nodejs"
            echo "  npm install -g @datadog/datadog-ci"
            echo "  exit"
            echo ""
            echo "⚠️  Deployment marking skipped"
            echo "⚠️  See RUNNER_SETUP_FIX.md for detailed instructions"
            exit 0
          fi

          echo "✓ Found datadog-ci: $(datadog-ci version)"
          
          # Mark deployment in Datadog
          if datadog-ci deployment mark \
            --env "$DD_ENV" \
            --service "$DD_SERVICE" \
            --revision "${{ steps.version.outputs.version }}" \
            --tags "deployment_method:self_hosted" \
            --tags "repository:${{ github.repository }}" \
            --tags "branch:${{ github.ref_name }}" \
            --tags "git_sha:$SHORT_SHA" \
            --tags "runner:containerized" \
            --no-fail; then
            echo ""
            echo "✅ Deployment marked successfully in Datadog"
            echo "🔗 View in Datadog: https://app.datadoghq.com/apm/services/$DD_SERVICE/deployments?env=$DD_ENV"
            echo ""
          else
            echo ""
            echo "❌ Failed to mark deployment in Datadog"
            echo "   Check DD_API_KEY and network connectivity"
            echo ""
          fi